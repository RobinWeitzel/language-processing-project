{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 8, 8, 1), (50000, 1, 4))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create images with random rectangles and bounding boxes. \n",
    "num_imgs = 50000\n",
    "\n",
    "img_size = 8\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "num_objects = 1\n",
    "color_size = 1\n",
    "\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "imgs = np.zeros((num_imgs, img_size, img_size, color_size))  # set background to 0\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size=2)\n",
    "        x = np.random.randint(0, img_size - w)\n",
    "        y = np.random.randint(0, img_size - h)\n",
    "        imgs[i_img, x:x+w, y:y+h, 0] = 1.  # set rectangle to 1\n",
    "        bboxes[i_img, i_object] = [x, y, w, h]\n",
    "        \n",
    "imgs.shape, bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACpZJREFUeJzt3W+IXneZh/Hru0mlTVQqWhZNWmJhaZWCtg61GijY1KVdS/eNsCkoKELe+KcVQXTfiO9F7IulEFr/QLuVNW1hKbvdCq0swprdaRq17VTQmrRpq0mQ2voHa/X2xTxdstkkc9I5Z56Zm+sDQ2YyZ8J9yFw55zlzcn6pKiT19FfzHkDSdAxcaszApcYMXGrMwKXGDFxqbFDgST6b5PEkjyW5O8m5Uw8mafVWDDzJNuAzwEJVXQZsAnZPPZik1Rt6ir4ZOC/JZmAL8Nx0I0kay+aVNqiqZ5N8BXga+D3wYFU9ePJ2SfYAewC2bt36nksvvXTsWSXNHDp0iOPHj2el7bLSrapJ3gTcA/wD8ALwHWBfVd15uq9ZWFioxcXFs5tY0mALCwssLi6uGPiQU/RrgZ9X1bGq+iNwL/D+1Q4oaXpDAn8auCrJliQBdgFL044laQwrBl5V+4F9wAHgx7Ov2TvxXJJGsOJFNoCq+hLwpYlnkTQy72STGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpMQOXGjNwqTEDlxozcKkxA5caM3CpsSErm1yS5OAJby8muWUthpO0OkMWPvgJ8G6AJJuAZ4H7Jp5L0gjO9hR9F/Czqjo8xTCSxnW2ge8G7p5iEEnjGxx4ktcBN7K8dNGpPr8nyWKSxWPHjo01n6RVOJsj+PXAgar65ak+WVV7q2qhqhYuuOCCcaaTtCpnE/hNeHoubSiDAk+yBfggywsPStoghi5d9DvgzRPPImlk3skmNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNTb0oYvnJ9mX5MkkS0neN/VgklZv0EMXgVuBB6rqw7MFELZMOJOkkawYeJI3AlcDHwOoqpeBl6cdS9IYhpyiXwwcA76R5NEktyfZevJGLl0krT9DAt8MXAHcVlWXA78FvnDyRi5dJK0/QwI/Ahypqv2zj/exHLykdW7FwKvqF8AzSS6Z/dYu4IlJp5I0iqFX0T8N3DW7gv4U8PHpRpI0lqFrkx0EFiaeRdLIvJNNaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgY9sinJIeAl4E/AK1Xl45ukDWDoQxcBPlBVxyebRNLoPEWXGhsaeAEPJnkkyZ5TbeDSRdL6MzTwnVV1BXA98MkkV5+8gUsXSevPoMCr6rnZr0eB+4ArpxxK0jhWDDzJ1iRvePV94G+Bx6YeTNLqDbmK/tfAfUle3f6fq+qBSaeSNIoVA6+qp4B3rcEskkbmj8mkxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqbHDgSTYleTTJ/VMOJGk8Z3MEvxlYmmoQSeMbFHiS7cCHgNunHUfSmIYewb8GfB748+k2cOkiaf0ZsvDBDcDRqnrkTNu5dJG0/gw5gu8EbpytEf5t4Jokd046laRRrBh4VX2xqrZX1Q5gN/BQVX1k8skkrZo/B5caG7I22f+qqu8B35tkEkmj8wguNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSYwYuNWbgUmMGLjVm4FJjBi41ZuBSY0Mem3xukv9O8sMkjyf58loMJmn1hjyT7Q/ANVX1myTnAN9P8u9V9YOJZ5O0SisGXlUF/Gb24Tmzt5pyKEnjGLo22aYkB4GjwHerav8ptnHpImmdGRR4Vf2pqt4NbAeuTHLZKbZx6SJpnTmrq+hV9QLLz0W/bpJpJI1qyFX0C5KcP3v/POBa4MmpB5O0ekOuor8V+FaSTSz/g/AvVXX/tGNJGsOQq+g/Ai5fg1kkjcw72aTGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGrMwKXGDFxqzMClxgxcaszApcYMXGpsyEMXL0zycJKl2dJFN6/FYJJWb8hDF18BPldVB5K8AXgkyXer6omJZ5O0Sisewavq+ao6MHv/JWAJ2Db1YJJW76xegyfZwfITVl26SNoABgee5PXAPcAtVfXiyZ936SJp/Rm6+OA5LMd9V1XdO+1IksYy5Cp6gDuApar66vQjSRrLkCP4TuCjwDVJDs7e/m7iuSSNYMjSRd8HsgazSBqZd7JJjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjU2JCHLn49ydEkj63FQJLGM+QI/k3guonnkDSBIUsX/SfwqzWYRdLIfA0uNTZkddFBkuwB9gBcdNFFY/2xWgs7dsDhw/OeYsM7BOyomvcY/8dogVfVXmAvwMLCwvraS53Z4cM++H4E6/Gb3lN0qbEhPya7G/gv4JIkR5J8YvqxJI1hyNJFN63FIJLG5ym61JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41JiBS40ZuNSYgUuNGbjUmIFLjRm41NigwJNcl+QnSX6a5AtTDyVpHEOeqroJ+CfgeuCdwE1J3jn1YJJWb8gR/Ergp1X1VFW9DHwb+Ptpx5I0hiErm2wDnjnh4yPAe0/e6MSli4A/NF1u+C3A8XkPMYGu+wVruG8ByJqtEXPJkI2GBH6qif/fKi0nLl2UZLGqFoYMsJG4XxtP131LsjhkuyGn6EeAC0/4eDvw3GsZStLaGhL4/wB/k+TtSV4H7Ab+ddqxJI1hyNJFryT5FPAfwCbg61X1+ApftneM4dYh92vj6bpvg/Yrtc7WM5Y0Hu9kkxozcKmxUQPveEtrkguTPJxkKcnjSW6e90xjS7IpyaNJ7p/3LGNJcn6SfUmenP3dvW/eM40lyWdn34uPJbk7ybmn23a0wBvf0voK8LmqegdwFfDJJvt1opuBpXkPMbJbgQeq6lLgXTTZvyTbgM8AC1V1GcsXvnefbvsxj+Atb2mtquer6sDs/ZdY/kbZNt+pxpNkO/Ah4PZ5zzKWJG8ErgbuAKiql6vqhflONarNwHlJNgNbOMN9KWMGfqpbWtuEAJBkB3A5sH++k4zqa8DngT/Pe5ARXQwcA74xe+lxe5Kt8x5qDFX1LPAV4GngeeDXVfXg6bYfM/BBt7RuVEleD9wD3FJVL857njEkuQE4WlWPzHuWkW0GrgBuq6rLgd8CXa4JvYnlM+O3A28Dtib5yOm2HzPwtre0JjmH5bjvqqp75z3PiHYCNyY5xPJLqmuS3DnfkUZxBDhSVa+eae1jOfgOrgV+XlXHquqPwL3A+0+38ZiBt7ylNUlYfi23VFVfnfc8Y6qqL1bV9qrawfLf10NVddqjwUZRVb8Ankny6v+42gU8MceRxvQ0cFWSLbPvzV2c4QLikP9NNshrvKV1I9gJfBT4cZKDs9/7x6r6tznOpJV9GrhrdrB5Cvj4nOcZRVXtT7IPOMDyT3ge5Qy3rXqrqtSYd7JJjRm41JiBS40ZuNSYgUuNGbjUmIFLjf0FV5ii9rLDWtIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.imshow(imgs[i].reshape(8, -1).T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "for bbox in bboxes[i]:\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], ec='r', fc='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 8, 8, 1), 3.880451515669847e-17, 1.0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape and normalize the image data to mean 0 and std 1. \n",
    "#X = (imgs.reshape(num_imgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "X = (imgs - np.mean(imgs)) / np.std(imgs)\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 4), 2.24976, 1.4011673498907973)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x, y, w, h by img_size, so that all values are between 0 and 1.\n",
    "# Important: Do not shift to negative values (e.g. by setting to mean 0), because the IOU calculation needs positive w and h.\n",
    "y = bboxes.reshape(num_imgs, -1) / img_size\n",
    "y.shape, np.mean(y), np.std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test.\n",
    "i = int(0.8 * num_imgs)\n",
    "train_X = X[:i]\n",
    "test_X = X[i:]\n",
    "train_y = y[:i]\n",
    "test_y = y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.fc1 = nn.Linear(36, 200)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc2 = nn.Linear(200, y.shape[-1])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = x.view(x.size(0), 1, 8, 8)\n",
    "        y = self.conv1(y)\n",
    "        #y = self.relu(y) \n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        #y = self.conv2(y)\n",
    "        y = self.maxpool(y)\n",
    "        y = self.relu(y)\n",
    "                        \n",
    "        # Flattening \n",
    "        y = y.view(y.size(0), -1)\n",
    "        \n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.dropout(y)\n",
    "        y = self.fc2(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Loss: 6.990885257720947\n",
      "Epoch 2/100\n",
      "Loss: 5.781137943267822\n",
      "Epoch 3/100\n",
      "Loss: 4.6541900634765625\n",
      "Epoch 4/100\n",
      "Loss: 3.5807013511657715\n",
      "Epoch 5/100\n",
      "Loss: 2.996645450592041\n",
      "Epoch 6/100\n",
      "Loss: 2.7590341567993164\n",
      "Epoch 7/100\n",
      "Loss: 2.564845561981201\n",
      "Epoch 8/100\n",
      "Loss: 2.40669846534729\n",
      "Epoch 9/100\n",
      "Loss: 2.2736308574676514\n",
      "Epoch 10/100\n",
      "Loss: 2.1794772148132324\n",
      "Epoch 11/100\n",
      "Loss: 2.1216959953308105\n",
      "Epoch 12/100\n",
      "Loss: 2.078296661376953\n",
      "Epoch 13/100\n",
      "Loss: 2.054555892944336\n",
      "Epoch 14/100\n",
      "Loss: 2.03230619430542\n",
      "Epoch 15/100\n",
      "Loss: 2.0225577354431152\n",
      "Epoch 16/100\n",
      "Loss: 2.0101425647735596\n",
      "Epoch 17/100\n",
      "Loss: 1.9997066259384155\n",
      "Epoch 18/100\n",
      "Loss: 1.9931418895721436\n",
      "Epoch 19/100\n",
      "Loss: 1.9912067651748657\n",
      "Epoch 20/100\n",
      "Loss: 1.9851099252700806\n",
      "Epoch 21/100\n",
      "Loss: 1.9821757078170776\n",
      "Epoch 22/100\n",
      "Loss: 1.9772411584854126\n",
      "Epoch 23/100\n",
      "Loss: 1.9758599996566772\n",
      "Epoch 24/100\n",
      "Loss: 1.969507098197937\n",
      "Epoch 25/100\n",
      "Loss: 1.9716682434082031\n",
      "Epoch 26/100\n",
      "Loss: 1.9683771133422852\n",
      "Epoch 27/100\n",
      "Loss: 1.9658931493759155\n",
      "Epoch 28/100\n",
      "Loss: 1.9665464162826538\n",
      "Epoch 29/100\n",
      "Loss: 1.964900255203247\n",
      "Epoch 30/100\n",
      "Loss: 1.966295838356018\n",
      "Epoch 31/100\n",
      "Loss: 1.9656190872192383\n",
      "Epoch 32/100\n",
      "Loss: 1.9717183113098145\n",
      "Epoch 33/100\n",
      "Loss: 1.9725944995880127\n",
      "Epoch 34/100\n",
      "Loss: 1.9852395057678223\n",
      "Epoch 35/100\n",
      "Loss: 1.9932082891464233\n",
      "Epoch 36/100\n",
      "Loss: 2.012019395828247\n",
      "Epoch 37/100\n",
      "Loss: 2.004303216934204\n",
      "Epoch 38/100\n",
      "Loss: 2.03251051902771\n",
      "Epoch 39/100\n",
      "Loss: 2.01212215423584\n",
      "Epoch 40/100\n",
      "Loss: 2.043520927429199\n",
      "Epoch 41/100\n",
      "Loss: 2.016097068786621\n",
      "Epoch 42/100\n",
      "Loss: 2.045423746109009\n",
      "Epoch 43/100\n",
      "Loss: 2.0126821994781494\n",
      "Epoch 44/100\n",
      "Loss: 2.037400245666504\n",
      "Epoch 45/100\n",
      "Loss: 2.0090718269348145\n",
      "Epoch 46/100\n",
      "Loss: 2.035877227783203\n",
      "Epoch 47/100\n",
      "Loss: 2.0053322315216064\n",
      "Epoch 48/100\n",
      "Loss: 2.02984356880188\n",
      "Epoch 49/100\n",
      "Loss: 2.002540349960327\n",
      "Epoch 50/100\n",
      "Loss: 2.025015354156494\n",
      "Epoch 51/100\n",
      "Loss: 2.000065326690674\n",
      "Epoch 52/100\n",
      "Loss: 2.021847724914551\n",
      "Epoch 53/100\n",
      "Loss: 1.9964563846588135\n",
      "Epoch 54/100\n",
      "Loss: 2.0175867080688477\n",
      "Epoch 55/100\n",
      "Loss: 1.997349739074707\n",
      "Epoch 56/100\n",
      "Loss: 2.015800714492798\n",
      "Epoch 57/100\n",
      "Loss: 1.994840383529663\n",
      "Epoch 58/100\n",
      "Loss: 2.0186657905578613\n",
      "Epoch 59/100\n",
      "Loss: 1.9962549209594727\n",
      "Epoch 60/100\n",
      "Loss: 2.01377534866333\n",
      "Epoch 61/100\n",
      "Loss: 1.9935696125030518\n",
      "Epoch 62/100\n",
      "Loss: 2.0141525268554688\n",
      "Epoch 63/100\n",
      "Loss: 1.9940375089645386\n",
      "Epoch 64/100\n",
      "Loss: 2.01175594329834\n",
      "Epoch 65/100\n",
      "Loss: 1.993138313293457\n",
      "Epoch 66/100\n",
      "Loss: 2.011136293411255\n",
      "Epoch 67/100\n",
      "Loss: 1.993029236793518\n",
      "Epoch 68/100\n",
      "Loss: 2.013228416442871\n",
      "Epoch 69/100\n",
      "Loss: 1.992106318473816\n",
      "Epoch 70/100\n",
      "Loss: 2.011820077896118\n",
      "Epoch 71/100\n",
      "Loss: 1.9910032749176025\n",
      "Epoch 72/100\n",
      "Loss: 2.012268304824829\n",
      "Epoch 73/100\n",
      "Loss: 1.9946376085281372\n",
      "Epoch 74/100\n",
      "Loss: 2.0137031078338623\n",
      "Epoch 75/100\n",
      "Loss: 1.9934509992599487\n",
      "Epoch 76/100\n",
      "Loss: 2.0117862224578857\n",
      "Epoch 77/100\n",
      "Loss: 1.99160897731781\n",
      "Epoch 78/100\n",
      "Loss: 2.013853073120117\n",
      "Epoch 79/100\n",
      "Loss: 1.9899077415466309\n",
      "Epoch 80/100\n",
      "Loss: 2.0116188526153564\n",
      "Epoch 81/100\n",
      "Loss: 1.995043158531189\n",
      "Epoch 82/100\n",
      "Loss: 2.012458324432373\n",
      "Epoch 83/100\n",
      "Loss: 1.993315577507019\n",
      "Epoch 84/100\n",
      "Loss: 2.0130093097686768\n",
      "Epoch 85/100\n",
      "Loss: 1.9909361600875854\n",
      "Epoch 86/100\n",
      "Loss: 2.014011859893799\n",
      "Epoch 87/100\n",
      "Loss: 1.9898079633712769\n",
      "Epoch 88/100\n",
      "Loss: 2.00994873046875\n",
      "Epoch 89/100\n",
      "Loss: 1.9899760484695435\n",
      "Epoch 90/100\n",
      "Loss: 2.0129165649414062\n",
      "Epoch 91/100\n",
      "Loss: 1.9896070957183838\n",
      "Epoch 92/100\n",
      "Loss: 2.012359142303467\n",
      "Epoch 93/100\n",
      "Loss: 1.9913471937179565\n",
      "Epoch 94/100\n",
      "Loss: 2.0120136737823486\n",
      "Epoch 95/100\n",
      "Loss: 1.9886432886123657\n",
      "Epoch 96/100\n",
      "Loss: 2.0105674266815186\n",
      "Epoch 97/100\n",
      "Loss: 1.9901132583618164\n",
      "Epoch 98/100\n",
      "Loss: 2.0136289596557617\n",
      "Epoch 99/100\n",
      "Loss: 1.9924280643463135\n",
      "Epoch 100/100\n",
      "Loss: 2.0126395225524902\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "#lr=1.0, rho=0.95, epsilon=None, decay=0.0\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.95)\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(\"Epoch\", str(e + 1) + '/' + str(epochs))\n",
    "    X_tensor = torch.from_numpy(train_X).float()\n",
    "    Y_tensor = torch.from_numpy(train_y).float()\n",
    "    optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "    outputs = model(X_tensor)                           # Forward pass: compute the output class given a review\n",
    "    loss = criterion(outputs, Y_tensor)               # Compute the loss: difference between the output class and the pre-given label\n",
    "    loss.backward()                                   # Backward pass: compute the weight\n",
    "    optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "    print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 4])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict bounding boxes on the test images.\n",
    "pred_y = model(torch.from_numpy(test_X).float())\n",
    "pred_bboxes = pred_y * img_size\n",
    "pred_bboxes = pred_bboxes.reshape(len(pred_bboxes), num_objects, -1)\n",
    "pred_bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0.\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a few images and predicted bounding boxes from the test dataset. \n",
    "plt.figure(figsize=(12, 3))\n",
    "for i_subplot in range(1, 5):\n",
    "    plt.subplot(1, 4, i_subplot)\n",
    "    i = np.random.randint(len(test_imgs))\n",
    "    plt.imshow(test_imgs[i].reshape(8, -1).T, cmap='Greys', interpolation='none', origin='lower', extent=[0, img_size, 0, img_size])\n",
    "    for pred_bbox, exp_bbox in zip(pred_bboxes[i], test_bboxes[i]):\n",
    "        plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], ec='r', fc='none'))\n",
    "        plt.annotate('IOU: {:.2f}'.format(IOU(pred_bbox, exp_bbox)), (pred_bbox[0], pred_bbox[1]+pred_bbox[3]+0.2), color='r')\n",
    "        \n",
    "# plt.savefig('plots/bw-single-rectangle_prediction.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean IOU (overlap) between the predicted and expected bounding boxes on the test dataset. \n",
    "summed_IOU = 0.\n",
    "for pred_bbox, test_bbox in zip(pred_bboxes.reshape(-1, 4), test_bboxes.reshape(-1, 4)):\n",
    "    summed_IOU += IOU(pred_bbox, test_bbox)\n",
    "mean_IOU = summed_IOU / len(pred_bboxes)\n",
    "mean_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
